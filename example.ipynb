{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qsi9ReuN3l75"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/plant-ai-biophysics-lab/DeformableCNN-PlantTraits/blob/main/example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ns2WG0013l76"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!git clone https://github.com/plant-ai-biophysics-lab/DeformableCNN-PlantTraits.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "APIwaipS3l76"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.chdir('/content/DeformableCNN-PlantTraits')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "W0AZQ2X73l76"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install albumentations==1.1.0\n",
        "!pip install agml\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FiIY5DLz3l76"
      },
      "source": [
        "# Training and Evaluation Pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jKCy8Dx3l76"
      },
      "source": [
        "### Data and config setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvzcYmjx3l76"
      },
      "source": [
        "Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "DYBj1pip3l76"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import torch, torchvision\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torch.functional import split\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import lr_scheduler\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "from datatools import *\n",
        "from engine import train_single_epoch, validate\n",
        "from loss import NMSELoss\n",
        "from architecture import GreenhouseMidFusionRegressor"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUAQjCAH3l77"
      },
      "source": [
        "Download 2021 Autonomous Greenhouse Challenge dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hqI934IF3l77",
        "outputId": "e8f4eec4-3265-4e41-9642-21ccf73327d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading autonomous_greenhouse_regression (size = 887.2 MB): 887226368it [00:50, 17579122.57it/s]                               \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[AgML Download]: Extracting files for autonomous_greenhouse_regression... Done!\n",
            "\n",
            "====================================================================================================\n",
            "You have just downloaded \u001b[1mautonomous_greenhouse_regression\u001b[0m.\n",
            "\n",
            "This dataset is licensed under the \u001b[1mCC BY-SA 4.0\u001b[0m license.\n",
            "To learn more, visit: https://creativecommons.org/licenses/by-sa/4.0/\n",
            "\n",
            "When using this dataset, please cite the following:\n",
            "\n",
            "@misc{https://doi.org/10.4121/15023088.v1,\n",
            "  doi = {10.4121/15023088.V1},\n",
            "  url = {https://data.4tu.nl/articles/_/15023088/1},\n",
            "  author = {Hemming,  S. (Silke) and de Zwart,  H.F. (Feije) and Elings,  A. (Anne) and bijlaard,  monique and Marrewijk,  van,  Bart and Petropoulou,  Anna},\n",
            "  keywords = {Horticultural Crops,  Mechanical Engineering,  FOS: Mechanical engineering,  Artificial Intelligence and Image Processing,  FOS: Computer and information sciences,  Horticultural Production,  FOS: Agriculture,  forestry and fisheries,  Autonomous Greenhouse Challenge,  autonomous greenhouse,  Artificial Intelligence,  image processing,  computer vision,  Horticulture,  Lettuce,  sensors,  non-destructive sensing},\n",
            "  title = {3rd Autonomous Greenhouse Challenge: Online Challenge Lettuce Images},\n",
            "  publisher = {4TU.ResearchData},\n",
            "  year = {2021},\n",
            "  copyright = {Creative Commons Attribution 4.0 International}\n",
            "}\n",
            "\n",
            "You can find additional information about this dataset at:\n",
            "https://data.4tu.nl/articles/dataset/3rd_Autonomous_Greenhouse_Challenge_Online_Challenge_Lettuce_Images/15023088/1\n",
            "\n",
            "This message will \u001b[1mnot\u001b[0m be automatically shown\n",
            "again. To view this message again, in an AgMLDataLoader\n",
            "run `loader.info.citation_summary()`. Otherwise, you\n",
            "can use `agml.data.source(<name>).citation_summary().`\n",
            "\n",
            "You can find your dataset at /content/DeformableCNN-PlantTraits/autonomous_greenhouse_regression.\n",
            "====================================================================================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "Received invalid info parameter: 'num_to_class'.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/agml/data/metadata.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;31m# Some weird behavior with lookups can happen.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/agml/data/metadata.py\u001b[0m in \u001b[0;36mnum_to_class\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    213\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m                     \u001b[0mnums\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m                     \u001b[0mout\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_type\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnums\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'keys'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-2fbc67e4142a>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0magml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAgMLDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'autonomous_greenhouse_regression'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/agml/data/loader.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;34m'classes'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;34m'num_classes'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0;34m'num_to_class'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_to_class\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m             \u001b[0;34m'class_to_num'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_to_num\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m             'data_distributions': {self.name: self._info.num_images}}\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/agml/data/metadata.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    155\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_metadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             raise AttributeError(\n\u001b[0m\u001b[1;32m    158\u001b[0m                 maybe_you_meant(\n\u001b[1;32m    159\u001b[0m                     \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf\"Received invalid info parameter: '{key}'.\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: Received invalid info parameter: 'num_to_class'."
          ]
        }
      ],
      "source": [
        "import agml\n",
        "loader = agml.data.AgMLDataLoader('autonomous_greenhouse_regression', dataset_path = './')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1myLiQl3l77"
      },
      "source": [
        "Define data and output directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "wdC-bUL93l77"
      },
      "outputs": [],
      "source": [
        "sav_dir='model_weights/'\n",
        "if not os.path.exists(sav_dir):\n",
        "    os.mkdir(sav_dir)\n",
        "# Comment these two lines and uncomment the next two if you've already croppped the images to another directory\n",
        "RGB_Data_Dir   = './autonomous_greenhouse_regression/images/'\n",
        "Depth_Data_Dir = './autonomous_greenhouse_regression/depth_images/'\n",
        "\n",
        "\n",
        "# RGB_Data_Dir='./autonomous_greenhouse_regression/cropped_images/'\n",
        "# Depth_Data_Dir='./autonomous_greenhouse_regression/cropped_depth_images/'\n",
        "\n",
        "\n",
        "JSON_Files_Dir = './autonomous_greenhouse_regression/annotations.json'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLVoPM7W3l77"
      },
      "source": [
        "Crop the data if necessary (if you did this beforehand or you don't need to crop don't run)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "OANt3ue_3l77"
      },
      "outputs": [],
      "source": [
        "# import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "min_x=650\n",
        "max_x=1450\n",
        "min_y=200\n",
        "max_y=900\n",
        "cropped_img_dir='./autonomous_greenhouse_regression/cropped_images/'\n",
        "\n",
        "cropped_depth_img_dir='./autonomous_greenhouse_regression/cropped_depth_images/'\n",
        "\n",
        "if not os.path.exists(cropped_img_dir):\n",
        "    os.mkdir(cropped_img_dir)\n",
        "\n",
        "if not os.path.exists(cropped_depth_img_dir):\n",
        "    os.mkdir(cropped_depth_img_dir)\n",
        "\n",
        "for im in os.listdir(RGB_Data_Dir):\n",
        "    img = cv2.imread(RGB_Data_Dir+im)\n",
        "    crop_img = img[min_y:max_y,min_x:max_x]\n",
        "    cv2.imwrite(cropped_img_dir+im, crop_img)\n",
        "\n",
        "for depth_im in os.listdir(Depth_Data_Dir):\n",
        "    depth_img = cv2.imread(Depth_Data_Dir+depth_im, 0)\n",
        "    crop_depth_img = depth_img[min_y:max_y,min_x:max_x]\n",
        "    cv2.imwrite(cropped_depth_img_dir+depth_im, crop_depth_img)\n",
        "\n",
        "RGB_Data_Dir   = cropped_img_dir\n",
        "Depth_Data_Dir = cropped_depth_img_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OoQY_UP3l78"
      },
      "source": [
        "Set model architectures options:\n",
        "- single vs. multi input (SI- or MI-)\n",
        "- single vs. multi output (-SO or -MO)\n",
        "- deformable vs. standard convolutions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jZfCjjge3l78"
      },
      "outputs": [],
      "source": [
        "ConvType = 'deformable' # 'standard'\n",
        "\n",
        "training_category = 'MIMO' #'MIMO', 'MISO', 'SIMO', 'SISO'\n",
        "\n",
        "# Multi-input, multi-output model\n",
        "if training_category   == 'MIMO':\n",
        "    inputs = ['RGB-D']\n",
        "    outputs = ['ALL']\n",
        "    NumOutputs = None\n",
        "\n",
        "# Multi-input, single-output model\n",
        "elif training_category == 'MISO':\n",
        "    inputs = ['RGB-D']\n",
        "    outputs = ['FreshWeightShoot','DryWeightShoot','Height','Diameter','LeafArea']\n",
        "    NumOutputs = 1\n",
        "\n",
        "# Single-input, multi-output model\n",
        "elif training_category == 'SIMO':\n",
        "    inputs = ['RGB','D']\n",
        "    outputs = ['ALL']\n",
        "    NumOutputs = None\n",
        "\n",
        "# Single-input, single-output model\n",
        "elif training_category == 'SISO':\n",
        "    inputs = ['RGB','D']\n",
        "    outputs = ['FreshWeightShoot','DryWeightShoot','Height','Diameter','LeafArea']\n",
        "    NumOutputs = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EU86B7ab3l78"
      },
      "source": [
        "Set other model config parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "isnUtac23l78"
      },
      "outputs": [],
      "source": [
        "split_seed = 12\n",
        "num_epochs = 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JgTcwv13l78"
      },
      "source": [
        "Create PyTorch dataset, create PyTorch dataloader, and split train/val/test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sU5qbtW33l78",
        "outputId": "e6ff49bf-00ed-49c5-a983-69a73262819c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Instantiate the PyTorch datalaoder the autonomous greenhouse dataset.\n",
        "dataset = GreenhouseDataset(rgb_dir = RGB_Data_Dir,\n",
        "                            d_dir = Depth_Data_Dir,\n",
        "                            jsonfile_dir = JSON_Files_Dir,\n",
        "                            transforms = get_transforms(train=False, means=[0,0,0,0],stds=[1,1,1,1]))\n",
        "if NumOutputs !=1:\n",
        "    NumOutputs=dataset.num_outputs\n",
        "\n",
        "# Remove last 50 images from training/validation set. These are the test set.\n",
        "dataset.df= dataset.df.iloc[:-50]\n",
        "\n",
        "# Split train and validation set. Stratify based on variety.\n",
        "train_split, val_split = train_test_split(dataset.df,\n",
        "                                          test_size = 0.2,\n",
        "                                          random_state = split_seed,\n",
        "                                          stratify = dataset.df['outputs'].str['classification']) #change to None if you don't have class info\n",
        "train = torch.utils.data.Subset(dataset, train_split.index.tolist())\n",
        "val   = torch.utils.data.Subset(dataset, val_split.index.tolist())\n",
        "\n",
        "# Create train and validation dataloaders\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size=6, num_workers=6, shuffle=True)\n",
        "val_loader   = torch.utils.data.DataLoader(val,   batch_size=6, shuffle=False, num_workers=6)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8sWuhBJ3l78"
      },
      "source": [
        "Determine the mean and standard deviation of images for normalization (Only need to do once for a new dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4uBb2AW3l78",
        "outputId": "12933740-d30b-40db-e40a-7bcc214d0820"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 12 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean: tensor([0.5482, 0.4620, 0.3602, 0.0127])\n",
            "Standard Deviation tensor([0.1639, 0.1761, 0.2659, 0.0035])\n"
          ]
        }
      ],
      "source": [
        "# this part is just to check the MEAN and STD of the dataset (dont run unless you need mu and sigma)\n",
        "\n",
        "nimages = 0\n",
        "mean = 0.\n",
        "std = 0.\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=5, shuffle=False, num_workers=12)\n",
        "dataset.input = 'RGB-D'\n",
        "dataset.out = 'ALL'\n",
        "for batch, _ in dataloader:\n",
        "\n",
        "    # Rearrange batch to be the shape of [B, C, W * H]\n",
        "    batch = batch.view(batch.size(0), batch.size(1), -1)\n",
        "    # Update total number of images\n",
        "    nimages += batch.size(0)\n",
        "    # Compute mean and std here\n",
        "    mean += batch.mean(2).sum(0)\n",
        "    std += batch.std(2).sum(0)\n",
        "\n",
        "# Final step\n",
        "mean /= nimages\n",
        "std /= nimages\n",
        "\n",
        "print('Mean: '+ str(mean))\n",
        "print('Standard Deviation', str(std))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiV137k03l78"
      },
      "source": [
        "Copy the output of the previous cells into here to avoid needing to redetermine mean and std every time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "V8QlAkmH3l78"
      },
      "outputs": [],
      "source": [
        "dataset.means=[0.5482, 0.4620, 0.3602, 0.0127]  #these values were copied from the previous cell\n",
        "dataset.stds=[0.1639, 0.1761, 0.2659, 0.0035]   #copy and paste the values to avoid having\n",
        "                                                # to rerun the previous cell for every iteration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwBrY_om3l79"
      },
      "source": [
        "Define the loss function as Normalized Mean Squared Error, as required for the 2021 Autonomous Greenhouse Challenge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "SVwBEWRE3l79"
      },
      "outputs": [],
      "source": [
        "criterion = NMSELoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkNYzFDx3l79"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0GvkCIp3l79"
      },
      "source": [
        "Define the training loop and fit the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xc1cXjr73l79",
        "outputId": "3e86e07e-ef91-4b03-98b3-7fe10c038fc0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch:  1 , Time Elapsed:  2.7060508728027343e-06  mins\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:617: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train NMSE:  4.970419406890869\n",
            "Train NMSE:  4.60944938659668\n",
            "Train NMSE:  3.8320040702819824\n",
            "Train NMSE:  3.3588671684265137\n",
            "Train NMSE:  3.020707607269287\n",
            "Train NMSE:  5.797316074371338\n",
            "Train NMSE:  3.4509828090667725\n",
            "Train NMSE:  3.4639430046081543\n",
            "Train NMSE:  2.705380916595459\n",
            "Train NMSE:  2.9257187843322754\n",
            "Train NMSE:  2.9639089107513428\n",
            "Train NMSE:  2.983748197555542\n",
            "Train NMSE:  2.9683423042297363\n",
            "Train NMSE:  2.691638231277466\n",
            "Train NMSE:  2.46527361869812\n",
            "Train NMSE:  2.965986490249634\n",
            "Train NMSE:  2.4960169792175293\n",
            "Train NMSE:  2.2979843616485596\n",
            "Train NMSE:  2.23479962348938\n",
            "Train NMSE:  2.0221686363220215\n",
            "Train NMSE:  2.0449557304382324\n",
            "Train NMSE:  3.023552179336548\n",
            "Train NMSE:  2.1492156982421875\n",
            "Train NMSE:  2.443488597869873\n",
            "Train NMSE:  2.3152503967285156\n",
            "Train NMSE:  2.3950610160827637\n",
            "Train NMSE:  2.1690661907196045\n",
            "Train NMSE:  2.2644739151000977\n",
            "Train NMSE:  2.014524459838867\n",
            "Train NMSE:  2.09029221534729\n",
            "Train NMSE:  2.442634105682373\n",
            "Train NMSE:  2.1145927906036377\n",
            "Train NMSE:  2.4553868770599365\n",
            "Train NMSE:  2.277578353881836\n",
            "Train NMSE:  2.192713737487793\n",
            "Train NMSE:  2.407979726791382\n",
            "Train NMSE:  1.920236587524414\n",
            "Train NMSE:  2.424182415008545\n",
            "Train NMSE:  1.9686765670776367\n",
            "Train NMSE:  2.0244274139404297\n",
            "Train NMSE:  2.090022325515747\n",
            "Train NMSE:  1.913740634918213\n",
            "Train NMSE:  2.3213675022125244\n",
            "Train NMSE:  1.758583426475525\n",
            "Train NMSE:  1.7446348667144775\n",
            "Validating and Checkpointing!\n",
            "Best model Saved! Val NMSE:  47.17815113067627\n",
            "Epoch:  2 , Time Elapsed:  2.002000403404236  mins\n",
            "Train NMSE:  1.8189347982406616\n",
            "Train NMSE:  2.1391167640686035\n",
            "Train NMSE:  2.123922348022461\n",
            "Train NMSE:  2.0889816284179688\n",
            "Train NMSE:  2.163154125213623\n",
            "Train NMSE:  1.595892071723938\n",
            "Train NMSE:  2.2132647037506104\n",
            "Train NMSE:  2.184356927871704\n",
            "Train NMSE:  1.7418686151504517\n",
            "Train NMSE:  1.6429660320281982\n",
            "Train NMSE:  2.2808563709259033\n",
            "Train NMSE:  1.5944161415100098\n",
            "Train NMSE:  2.1545040607452393\n",
            "Train NMSE:  1.9488894939422607\n",
            "Train NMSE:  2.1204545497894287\n",
            "Train NMSE:  2.0814170837402344\n",
            "Train NMSE:  1.8656494617462158\n",
            "Train NMSE:  2.2264037132263184\n",
            "Train NMSE:  1.6001293659210205\n",
            "Train NMSE:  1.6520497798919678\n",
            "Train NMSE:  1.5480093955993652\n",
            "Train NMSE:  1.4637858867645264\n",
            "Train NMSE:  1.555577039718628\n",
            "Train NMSE:  1.5233874320983887\n",
            "Train NMSE:  1.6447147130966187\n",
            "Train NMSE:  1.6095293760299683\n",
            "Train NMSE:  1.5335859060287476\n",
            "Train NMSE:  1.4924465417861938\n",
            "Train NMSE:  1.4830329418182373\n",
            "Train NMSE:  1.8050825595855713\n",
            "Train NMSE:  1.3413945436477661\n",
            "Train NMSE:  1.596214771270752\n",
            "Train NMSE:  1.6242084503173828\n",
            "Train NMSE:  1.6616182327270508\n",
            "Train NMSE:  1.640936255455017\n",
            "Train NMSE:  1.618079662322998\n",
            "Train NMSE:  1.7868826389312744\n",
            "Train NMSE:  1.720173954963684\n",
            "Train NMSE:  1.389434814453125\n",
            "Train NMSE:  1.9577698707580566\n",
            "Train NMSE:  1.408379077911377\n",
            "Train NMSE:  1.5990204811096191\n",
            "Train NMSE:  1.470572829246521\n",
            "Train NMSE:  1.4847581386566162\n",
            "Train NMSE:  1.289076328277588\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val NMSE:  78.37369871139526 Best Val NMSE:  47.17815113067627\n",
            "Epoch:  3 , Time Elapsed:  3.9705741008122764  mins\n",
            "Train NMSE:  1.2573168277740479\n",
            "Train NMSE:  1.5260510444641113\n",
            "Train NMSE:  1.3709161281585693\n",
            "Train NMSE:  1.3183071613311768\n",
            "Train NMSE:  1.290401577949524\n",
            "Train NMSE:  2.1697380542755127\n",
            "Train NMSE:  1.2473423480987549\n",
            "Train NMSE:  1.3535573482513428\n",
            "Train NMSE:  1.658847451210022\n",
            "Train NMSE:  1.8120195865631104\n",
            "Train NMSE:  1.5151962041854858\n",
            "Train NMSE:  1.56205153465271\n",
            "Train NMSE:  1.5018481016159058\n",
            "Train NMSE:  1.6967120170593262\n",
            "Train NMSE:  1.1512340307235718\n",
            "Train NMSE:  1.200937032699585\n",
            "Train NMSE:  1.4756985902786255\n",
            "Train NMSE:  1.3008071184158325\n",
            "Train NMSE:  1.0726416110992432\n",
            "Train NMSE:  1.4462679624557495\n",
            "Train NMSE:  1.1628810167312622\n",
            "Train NMSE:  1.127375602722168\n",
            "Train NMSE:  1.204317331314087\n",
            "Train NMSE:  1.341858983039856\n",
            "Train NMSE:  1.4017863273620605\n",
            "Train NMSE:  0.9905088543891907\n",
            "Train NMSE:  1.1360054016113281\n",
            "Train NMSE:  1.14643394947052\n",
            "Train NMSE:  1.1782691478729248\n",
            "Train NMSE:  1.363433599472046\n",
            "Train NMSE:  1.2238706350326538\n",
            "Train NMSE:  1.0506353378295898\n",
            "Train NMSE:  1.1895943880081177\n",
            "Train NMSE:  1.173685908317566\n",
            "Train NMSE:  1.7588841915130615\n",
            "Train NMSE:  1.1605770587921143\n",
            "Train NMSE:  1.0298711061477661\n",
            "Train NMSE:  1.2293331623077393\n",
            "Train NMSE:  1.0661793947219849\n",
            "Train NMSE:  1.549489140510559\n",
            "Train NMSE:  1.0618354082107544\n",
            "Train NMSE:  0.9988541007041931\n",
            "Train NMSE:  1.2615360021591187\n",
            "Train NMSE:  1.4325882196426392\n",
            "Train NMSE:  0.9916501045227051\n",
            "Validating and Checkpointing!\n",
            "Best model Saved! Val NMSE:  37.62612521648407\n",
            "Epoch:  4 , Time Elapsed:  5.940089499950409  mins\n",
            "Train NMSE:  1.2786945104599\n",
            "Train NMSE:  1.0794894695281982\n",
            "Train NMSE:  1.273352861404419\n",
            "Train NMSE:  1.0973026752471924\n",
            "Train NMSE:  1.2872613668441772\n",
            "Train NMSE:  1.0095009803771973\n",
            "Train NMSE:  1.2626091241836548\n",
            "Train NMSE:  1.0089051723480225\n",
            "Train NMSE:  1.1984889507293701\n",
            "Train NMSE:  1.3863160610198975\n",
            "Train NMSE:  1.128800868988037\n",
            "Train NMSE:  1.1119846105575562\n",
            "Train NMSE:  1.0525567531585693\n",
            "Train NMSE:  1.1290587186813354\n",
            "Train NMSE:  0.9133630990982056\n",
            "Train NMSE:  1.1599596738815308\n",
            "Train NMSE:  1.3214879035949707\n",
            "Train NMSE:  1.0148000717163086\n",
            "Train NMSE:  1.1318387985229492\n",
            "Train NMSE:  1.4682676792144775\n",
            "Train NMSE:  1.1039392948150635\n",
            "Train NMSE:  1.0840924978256226\n",
            "Train NMSE:  1.2067430019378662\n",
            "Train NMSE:  1.154379963874817\n",
            "Train NMSE:  1.9935427904129028\n",
            "Train NMSE:  1.146776556968689\n",
            "Train NMSE:  1.5670251846313477\n",
            "Train NMSE:  1.3173450231552124\n",
            "Train NMSE:  1.89943528175354\n",
            "Train NMSE:  0.9156453013420105\n",
            "Train NMSE:  1.8006142377853394\n",
            "Train NMSE:  1.1918063163757324\n",
            "Train NMSE:  1.0860480070114136\n",
            "Train NMSE:  1.6237963438034058\n",
            "Train NMSE:  1.0405819416046143\n",
            "Train NMSE:  1.3735010623931885\n",
            "Train NMSE:  1.3566535711288452\n",
            "Train NMSE:  1.1628046035766602\n",
            "Train NMSE:  1.0511434078216553\n",
            "Train NMSE:  4.559988021850586\n",
            "Train NMSE:  1.677971601486206\n",
            "Train NMSE:  2.0202765464782715\n",
            "Train NMSE:  2.899761199951172\n",
            "Train NMSE:  2.580200672149658\n",
            "Train NMSE:  2.466479778289795\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val NMSE:  37.664857268333435 Best Val NMSE:  37.62612521648407\n",
            "Epoch:  5 , Time Elapsed:  7.900945949554443  mins\n",
            "Train NMSE:  3.0466973781585693\n",
            "Train NMSE:  2.042226791381836\n",
            "Train NMSE:  2.0331804752349854\n",
            "Train NMSE:  2.486697196960449\n",
            "Train NMSE:  2.2562618255615234\n",
            "Train NMSE:  2.0610296726226807\n",
            "Train NMSE:  1.767069697380066\n",
            "Train NMSE:  1.7204935550689697\n",
            "Train NMSE:  1.8637911081314087\n",
            "Train NMSE:  1.4909967184066772\n",
            "Train NMSE:  1.3959481716156006\n",
            "Train NMSE:  1.3622832298278809\n",
            "Train NMSE:  2.739621162414551\n",
            "Train NMSE:  2.4157960414886475\n",
            "Train NMSE:  1.4521616697311401\n",
            "Train NMSE:  1.5266735553741455\n",
            "Train NMSE:  1.772472620010376\n",
            "Train NMSE:  1.6425591707229614\n",
            "Train NMSE:  1.495265007019043\n",
            "Train NMSE:  1.3382781744003296\n",
            "Train NMSE:  0.9820396304130554\n",
            "Train NMSE:  1.0827096700668335\n",
            "Train NMSE:  1.1139957904815674\n",
            "Train NMSE:  1.0979442596435547\n",
            "Train NMSE:  1.0540777444839478\n",
            "Train NMSE:  0.971291184425354\n",
            "Train NMSE:  1.1586074829101562\n",
            "Train NMSE:  1.2127934694290161\n",
            "Train NMSE:  1.390895128250122\n",
            "Train NMSE:  1.2059646844863892\n",
            "Train NMSE:  1.0633114576339722\n",
            "Train NMSE:  1.186456561088562\n",
            "Train NMSE:  1.4159388542175293\n",
            "Train NMSE:  1.2622146606445312\n",
            "Train NMSE:  1.027231216430664\n",
            "Train NMSE:  1.056090235710144\n",
            "Train NMSE:  1.3254259824752808\n",
            "Train NMSE:  1.0183664560317993\n",
            "Train NMSE:  1.0545191764831543\n",
            "Train NMSE:  1.1219176054000854\n",
            "Train NMSE:  1.1613682508468628\n",
            "Train NMSE:  1.0696845054626465\n",
            "Train NMSE:  1.1404225826263428\n",
            "Train NMSE:  1.1775845289230347\n",
            "Train NMSE:  1.3562822341918945\n",
            "Validating and Checkpointing!\n",
            "Best model Saved! Val NMSE:  18.209189534187317\n",
            "Epoch:  6 , Time Elapsed:  9.870543392499288  mins\n",
            "Train NMSE:  1.069040298461914\n",
            "Train NMSE:  1.046439290046692\n",
            "Train NMSE:  0.8892084956169128\n",
            "Train NMSE:  1.0669867992401123\n",
            "Train NMSE:  1.515528678894043\n",
            "Train NMSE:  1.1827808618545532\n",
            "Train NMSE:  1.0874099731445312\n",
            "Train NMSE:  1.490640640258789\n",
            "Train NMSE:  1.0114789009094238\n",
            "Train NMSE:  1.1000032424926758\n",
            "Train NMSE:  0.8571943044662476\n",
            "Train NMSE:  0.9980658292770386\n",
            "Train NMSE:  0.9635109901428223\n",
            "Train NMSE:  1.075634479522705\n",
            "Train NMSE:  0.9479532241821289\n",
            "Train NMSE:  0.961685061454773\n",
            "Train NMSE:  1.6433099508285522\n",
            "Train NMSE:  0.8232672810554504\n",
            "Train NMSE:  1.0984513759613037\n",
            "Train NMSE:  1.3154271841049194\n",
            "Train NMSE:  0.9953308701515198\n",
            "Train NMSE:  1.167982816696167\n",
            "Train NMSE:  0.9322004914283752\n",
            "Train NMSE:  0.9229961037635803\n",
            "Train NMSE:  0.8668972253799438\n",
            "Train NMSE:  0.938982367515564\n",
            "Train NMSE:  1.0282487869262695\n",
            "Train NMSE:  1.3921009302139282\n",
            "Train NMSE:  0.9694055318832397\n",
            "Train NMSE:  4.644464492797852\n",
            "Train NMSE:  1.5889763832092285\n",
            "Train NMSE:  1.64337158203125\n",
            "Train NMSE:  1.9445586204528809\n",
            "Train NMSE:  2.848165273666382\n",
            "Train NMSE:  1.9682576656341553\n",
            "Train NMSE:  1.7584729194641113\n",
            "Train NMSE:  1.1435856819152832\n",
            "Train NMSE:  1.1175105571746826\n",
            "Train NMSE:  0.9584938287734985\n",
            "Train NMSE:  1.1485366821289062\n",
            "Train NMSE:  0.9436808824539185\n",
            "Train NMSE:  1.4757567644119263\n",
            "Train NMSE:  1.1691851615905762\n",
            "Train NMSE:  2.13041615486145\n",
            "Train NMSE:  1.4022777080535889\n",
            "Validating and Checkpointing!\n",
            "Best model Saved! Val NMSE:  12.958776354789734\n",
            "Epoch:  7 , Time Elapsed:  11.83705095052719  mins\n",
            "Train NMSE:  0.9361132383346558\n",
            "Train NMSE:  1.3468763828277588\n",
            "Train NMSE:  0.942196786403656\n",
            "Train NMSE:  1.640195369720459\n",
            "Train NMSE:  1.7233917713165283\n",
            "Train NMSE:  1.4067100286483765\n",
            "Train NMSE:  1.160139799118042\n",
            "Train NMSE:  1.1736010313034058\n",
            "Train NMSE:  1.2048143148422241\n",
            "Train NMSE:  1.2735666036605835\n",
            "Train NMSE:  1.1823594570159912\n",
            "Train NMSE:  0.9246990084648132\n",
            "Train NMSE:  1.1402844190597534\n",
            "Train NMSE:  0.9682143926620483\n",
            "Train NMSE:  1.5502586364746094\n",
            "Train NMSE:  0.8955579400062561\n",
            "Train NMSE:  0.8379263877868652\n",
            "Train NMSE:  1.123134732246399\n",
            "Train NMSE:  1.2322278022766113\n",
            "Train NMSE:  1.0560550689697266\n",
            "Train NMSE:  1.4736089706420898\n",
            "Train NMSE:  1.361532211303711\n",
            "Train NMSE:  1.0291409492492676\n",
            "Train NMSE:  1.6233646869659424\n",
            "Train NMSE:  1.090879201889038\n",
            "Train NMSE:  1.02444326877594\n",
            "Train NMSE:  1.5251634120941162\n",
            "Train NMSE:  1.0058215856552124\n",
            "Train NMSE:  0.7806840538978577\n",
            "Train NMSE:  0.7686197757720947\n",
            "Train NMSE:  1.260480523109436\n",
            "Train NMSE:  1.0076919794082642\n",
            "Train NMSE:  0.8998022079467773\n",
            "Train NMSE:  0.9124423265457153\n",
            "Train NMSE:  1.2636170387268066\n",
            "Train NMSE:  1.0117127895355225\n",
            "Train NMSE:  1.2304884195327759\n",
            "Train NMSE:  1.394545555114746\n",
            "Train NMSE:  1.2358860969543457\n",
            "Train NMSE:  1.7737994194030762\n",
            "Train NMSE:  1.1883066892623901\n",
            "Train NMSE:  1.2273856401443481\n",
            "Train NMSE:  0.8979876041412354\n",
            "Train NMSE:  0.9804372191429138\n",
            "Train NMSE:  0.9859039187431335\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val NMSE:  13.848454594612122 Best Val NMSE:  12.958776354789734\n",
            "Epoch:  8 , Time Elapsed:  13.802048091093699  mins\n",
            "Train NMSE:  1.0272011756896973\n",
            "Train NMSE:  1.0776400566101074\n",
            "Train NMSE:  1.052970051765442\n",
            "Train NMSE:  1.0915639400482178\n",
            "Train NMSE:  1.0143035650253296\n",
            "Train NMSE:  1.589787483215332\n",
            "Train NMSE:  0.9117094278335571\n",
            "Train NMSE:  1.0253190994262695\n",
            "Train NMSE:  1.15940260887146\n",
            "Train NMSE:  1.0284982919692993\n",
            "Train NMSE:  0.7671526074409485\n",
            "Train NMSE:  2.3305397033691406\n",
            "Train NMSE:  1.0020947456359863\n",
            "Train NMSE:  1.11380136013031\n",
            "Train NMSE:  1.0434820652008057\n",
            "Train NMSE:  1.320104718208313\n",
            "Train NMSE:  1.3127286434173584\n",
            "Train NMSE:  1.1457656621932983\n",
            "Train NMSE:  0.7820621132850647\n",
            "Train NMSE:  1.2507355213165283\n",
            "Train NMSE:  0.902566134929657\n",
            "Train NMSE:  1.4170401096343994\n",
            "Train NMSE:  0.7959450483322144\n",
            "Train NMSE:  0.7897027730941772\n",
            "Train NMSE:  0.7152033448219299\n",
            "Train NMSE:  0.8751981854438782\n",
            "Train NMSE:  0.9094880819320679\n",
            "Train NMSE:  1.3676855564117432\n",
            "Train NMSE:  0.8748230934143066\n",
            "Train NMSE:  1.221023440361023\n",
            "Train NMSE:  0.9818148612976074\n",
            "Train NMSE:  0.8336968421936035\n",
            "Train NMSE:  0.8304057121276855\n",
            "Train NMSE:  1.0462266206741333\n",
            "Train NMSE:  1.1779258251190186\n",
            "Train NMSE:  1.128045678138733\n",
            "Train NMSE:  1.0751029253005981\n",
            "Train NMSE:  1.148690938949585\n",
            "Train NMSE:  1.058385968208313\n",
            "Train NMSE:  1.1179121732711792\n",
            "Train NMSE:  1.9697442054748535\n",
            "Train NMSE:  0.7231783866882324\n",
            "Train NMSE:  0.8999523520469666\n",
            "Train NMSE:  1.1302199363708496\n",
            "Train NMSE:  0.721347451210022\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val NMSE:  15.979297041893005 Best Val NMSE:  12.958776354789734\n",
            "Epoch:  9 , Time Elapsed:  15.773388453324635  mins\n",
            "Train NMSE:  0.6665971875190735\n",
            "Train NMSE:  0.7519876956939697\n",
            "Train NMSE:  0.7573195099830627\n",
            "Train NMSE:  0.9789848327636719\n",
            "Train NMSE:  0.6725561618804932\n",
            "Train NMSE:  0.7933213710784912\n",
            "Train NMSE:  2.417402505874634\n",
            "Train NMSE:  0.9525367617607117\n",
            "Train NMSE:  1.0923992395401\n",
            "Train NMSE:  1.0399988889694214\n",
            "Train NMSE:  1.208927869796753\n",
            "Train NMSE:  0.992283046245575\n",
            "Train NMSE:  0.9769222736358643\n",
            "Train NMSE:  0.798397958278656\n",
            "Train NMSE:  1.1442722082138062\n",
            "Train NMSE:  0.8842014670372009\n",
            "Train NMSE:  1.2050743103027344\n",
            "Train NMSE:  1.0815256834030151\n",
            "Train NMSE:  0.9923174381256104\n",
            "Train NMSE:  0.8917101621627808\n",
            "Train NMSE:  1.0822646617889404\n",
            "Train NMSE:  0.7517518997192383\n",
            "Train NMSE:  0.9001215696334839\n",
            "Train NMSE:  0.8400670289993286\n",
            "Train NMSE:  1.2633916139602661\n",
            "Train NMSE:  0.7844122648239136\n",
            "Train NMSE:  1.6275973320007324\n",
            "Train NMSE:  0.697906494140625\n",
            "Train NMSE:  1.0399092435836792\n",
            "Train NMSE:  0.8534567952156067\n",
            "Train NMSE:  0.7283275127410889\n",
            "Train NMSE:  1.738227367401123\n",
            "Train NMSE:  0.7142307758331299\n",
            "Train NMSE:  1.470333218574524\n",
            "Train NMSE:  0.8007174730300903\n",
            "Train NMSE:  0.8217823505401611\n",
            "Train NMSE:  0.7573644518852234\n",
            "Train NMSE:  0.9347332715988159\n",
            "Train NMSE:  1.0184171199798584\n",
            "Train NMSE:  0.7094784379005432\n",
            "Train NMSE:  1.0138651132583618\n",
            "Train NMSE:  0.8472923636436462\n",
            "Train NMSE:  0.7564188241958618\n",
            "Train NMSE:  1.0867061614990234\n",
            "Train NMSE:  0.9031299352645874\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val NMSE:  20.260660111904144 Best Val NMSE:  12.958776354789734\n",
            "Epoch:  10 , Time Elapsed:  17.759845213095346  mins\n",
            "Train NMSE:  1.004765510559082\n",
            "Train NMSE:  1.0744709968566895\n",
            "Train NMSE:  0.8922053575515747\n",
            "Train NMSE:  0.8461796641349792\n",
            "Train NMSE:  0.6214248538017273\n",
            "Train NMSE:  0.7067615985870361\n",
            "Train NMSE:  0.9544675946235657\n",
            "Train NMSE:  0.724463701248169\n",
            "Train NMSE:  0.8247451782226562\n",
            "Train NMSE:  0.828896164894104\n",
            "Train NMSE:  0.8273276090621948\n",
            "Train NMSE:  0.5749972462654114\n",
            "Train NMSE:  0.7673479318618774\n",
            "Train NMSE:  0.5566585063934326\n",
            "Train NMSE:  0.5878453254699707\n",
            "Train NMSE:  1.1071462631225586\n",
            "Train NMSE:  0.6239508390426636\n",
            "Train NMSE:  0.8747386932373047\n",
            "Train NMSE:  0.9558646082878113\n",
            "Train NMSE:  0.5739849209785461\n",
            "Train NMSE:  0.804542601108551\n",
            "Train NMSE:  0.7968058586120605\n",
            "Train NMSE:  0.6109853982925415\n",
            "Train NMSE:  0.6850715279579163\n",
            "Train NMSE:  0.9664501547813416\n",
            "Train NMSE:  0.6984231472015381\n",
            "Train NMSE:  0.9524169564247131\n",
            "Train NMSE:  0.8404822945594788\n",
            "Train NMSE:  0.7552536725997925\n",
            "Train NMSE:  0.6069207191467285\n",
            "Train NMSE:  0.7922718524932861\n",
            "Train NMSE:  0.9102776050567627\n",
            "Train NMSE:  0.8382135629653931\n",
            "Train NMSE:  1.7681751251220703\n",
            "Train NMSE:  0.8688777685165405\n",
            "Train NMSE:  0.8730404376983643\n",
            "Train NMSE:  0.9212239384651184\n",
            "Train NMSE:  0.9754801392555237\n",
            "Train NMSE:  1.081587314605713\n",
            "Train NMSE:  0.5857619047164917\n",
            "Train NMSE:  0.8410632610321045\n",
            "Train NMSE:  0.5668242573738098\n",
            "Train NMSE:  1.8395962715148926\n",
            "Train NMSE:  0.532556414604187\n",
            "Train NMSE:  0.657599687576294\n",
            "Validating and Checkpointing!\n",
            "Model is not good (might be overfitting)! Current val NMSE:  16.010629653930664 Best Val NMSE:  12.958776354789734\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "device = torch.device('cuda')\n",
        "\n",
        "for input in inputs:\n",
        "    for output in outputs:\n",
        "        dataset.input = input\n",
        "        dataset.out = output\n",
        "        model = GreenhouseMidFusionRegressor(input_data_type = input, num_outputs = NumOutputs, conv_type = ConvType)\n",
        "        model.to(device)\n",
        "        params = [p for p in model.parameters() if p.requires_grad]\n",
        "\n",
        "        optimizer = torch.optim.Adam(params,\n",
        "                                     lr=0.0005,\n",
        "                                     betas=(0.9, 0.999),\n",
        "                                     eps=1e-08,\n",
        "                                     weight_decay = 0,\n",
        "                                     amsgrad = False)  # select an optimzer for each run\n",
        "\n",
        "\n",
        "        best_val_loss = 9999999 # initial dummy value\n",
        "        current_val_loss = 0\n",
        "        # training_val_loss=0\n",
        "\n",
        "        writer = SummaryWriter()\n",
        "        start = time.time()\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            with open('run.txt', 'a') as f:\n",
        "                f.write('\\n')\n",
        "                f.write('Epoch: '+ str(epoch + 1) + ', Time Elapsed: '+ str((time.time()-start)/60) + ' mins')\n",
        "            print('Epoch: ', str(epoch + 1), ', Time Elapsed: ', str((time.time()-start)/60), ' mins')\n",
        "\n",
        "            train_single_epoch(model, dataset, device, criterion, optimizer, writer, epoch, train_loader)\n",
        "\n",
        "            best_val_loss = validate(model, dataset, device, training_category, sav_dir, criterion, writer, epoch, val_loader, best_val_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CPnUEq03l79"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3NY6k_S3l79"
      },
      "source": [
        "Define the test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "L9awrQug3l79"
      },
      "outputs": [],
      "source": [
        "# Instantiate the PyTorch datalaoder the autonomous greenhouse dataset.\n",
        "testset = GreenhouseDataset(rgb_dir = RGB_Data_Dir,\n",
        "                            d_dir = Depth_Data_Dir,\n",
        "                            jsonfile_dir = JSON_Files_Dir,\n",
        "                            transforms = get_transforms(train=False, means=dataset.means, stds=dataset.stds))\n",
        "\n",
        "# Grab last 50 images as test dataset\n",
        "testset.df = testset.df[-50:]\n",
        "\n",
        "# Get testset_size\n",
        "testset_size = testset.df.shape[0]\n",
        "\n",
        "# Create test dataloader\n",
        "test_loader = torch.utils.data.DataLoader(testset,\n",
        "                                          batch_size = 50,\n",
        "                                          num_workers = 0,\n",
        "                                          shuffle = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "esPy96ZU3l79"
      },
      "source": [
        "Define loss functions for model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "4dtA8IIk3l79"
      },
      "outputs": [],
      "source": [
        "cri = NMSELoss()\n",
        "mse = nn.MSELoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsqlkum83l79"
      },
      "source": [
        "Run the evaluation Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "Vz7Ti4bT3l7-",
        "outputId": "ee470590-bd29-4522-d013-9e49a23286d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input is  RGB-D\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "<ipython-input-21-403103bfbc78>:18: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(sav_dir + 'bestmodel' + training_category + '_' + input + '_' + output + '.pth'))\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacity of 14.75 GiB of which 889.06 MiB is free. Process 10715 has 13.88 GiB memory in use. Of the allocated memory 10.74 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-403103bfbc78>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m                 \u001b[0mrgbd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrgbd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m                 \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m                 \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgbd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m                 \u001b[0;31m# mse_loss=mse(preds, targets)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m                 \u001b[0;31m# nmse=criterion(preds, targets)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/DeformableCNN-PlantTraits/architecture.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inp)\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0mx_rgb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mx_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m             \u001b[0mx_rgb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrgbencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_rgb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0mx_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdepthencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_rgb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;31m# See note [TorchScript super()]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/DeformableCNN-PlantTraits/architecture.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moffset_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeformable_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moffset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mweight_replace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/ops/deform_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, offset, mask)\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0mmasks\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mapplied\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0mposition\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mconvolution\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \"\"\"\n\u001b[0;32m--> 170\u001b[0;31m         return deform_conv2d(\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/ops/deform_conv.py\u001b[0m in \u001b[0;36mdeform_conv2d\u001b[0;34m(input, offset, weight, bias, stride, padding, dilation, mask)\u001b[0m\n\u001b[1;32m     90\u001b[0m         )\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m     return torch.ops.torchvision.deform_conv2d(\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1114\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_has_torchbind_op_overload\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0m_must_dispatch_in_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_call_overload_packet_from_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;31m# TODO: use this to make a __dir__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 1.67 GiB. GPU 0 has a total capacity of 14.75 GiB of which 889.06 MiB is free. Process 10715 has 13.88 GiB memory in use. Of the allocated memory 10.74 GiB is allocated by PyTorch, and 3.00 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "# Evaluation loop\n",
        "device=torch.device('cuda')\n",
        "\n",
        "with torch.no_grad():\n",
        "    for input in inputs:\n",
        "        final = torch.zeros((testset_size,0))\n",
        "        all_targets = torch.zeros((testset_size,0))\n",
        "        for output in outputs:\n",
        "            print('Input is ', input)\n",
        "            testset.input = input\n",
        "            testset.out = output\n",
        "\n",
        "            device=torch.device('cuda')\n",
        "            model= GreenhouseMidFusionRegressor(input_data_type = input,\n",
        "                                                num_outputs = NumOutputs,\n",
        "                                                conv_type = ConvType)\n",
        "            model.to(device)\n",
        "            model.load_state_dict(torch.load(sav_dir + 'bestmodel' + training_category + '_' + input + '_' + output + '.pth'))\n",
        "            model.eval()\n",
        "\n",
        "\n",
        "            if output=='All':\n",
        "                ap=torch.zeros((0,5))\n",
        "                at=torch.zeros((0,5))\n",
        "            else:\n",
        "                ap=torch.zeros((0,1))\n",
        "                at=torch.zeros((0,1))\n",
        "\n",
        "            for rgbd, targets in test_loader:\n",
        "                rgbd = rgbd.to(device)\n",
        "                targets = targets.to(device)\n",
        "                preds = model(rgbd)\n",
        "                # mse_loss=mse(preds, targets)\n",
        "                # nmse=criterion(preds, targets)\n",
        "                # nmse, pred=cri(preds, targets)\n",
        "                ap=torch.cat((ap, preds.detach().cpu()), 0)\n",
        "                at=torch.cat((at, targets.detach().cpu()), 0)\n",
        "\n",
        "            if output=='All':\n",
        "                print('FW MSE: ', str(mse(ap[:,0],at[:,0]).tolist()))\n",
        "                print('DW MSE: ', str(mse(ap[:,1],at[:,1]).tolist()))\n",
        "                print('H MSE: ', str(mse(ap[:,2],at[:,2]).tolist()))\n",
        "                print('D MSE: ', str(mse(ap[:,3],at[:,3]).tolist()))\n",
        "                print('LA MSE: ', str(mse(ap[:,4],at[:,4]).tolist()))\n",
        "            else:\n",
        "                final=torch.cat((final, ap.detach().cpu()),1)\n",
        "                all_targets=torch.cat((all_targets, at.detach().cpu()),1)\n",
        "                print(output,' MSE: ', str(mse(ap,at).tolist()))\n",
        "\n",
        "        if output == 'All':\n",
        "            print('Overall NMSE: ', str(cri(ap,at).tolist()))\n",
        "        else:\n",
        "            print('Overall NMSE: ', str(cri(final,all_targets).tolist()))"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "52f36c1f6eb8678621dd418d5b8ad0837811436cfff124e7936f8a687fb60368"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}